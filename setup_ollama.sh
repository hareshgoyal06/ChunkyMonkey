#!/bin/bash

echo "ğŸ’ Setting up Ollama for ChunkyMonkey..."

# Check if Ollama is already installed
if command -v ollama &> /dev/null; then
    echo "âœ… Ollama is already installed"
else
    echo "ğŸ“¥ Installing Ollama..."
    curl -fsSL https://ollama.ai/install.sh | sh
fi

# Start Ollama service
echo "ğŸ”§ Starting Ollama service..."
ollama serve &
OLLAMA_PID=$!

# Wait for service to start
echo "â³ Waiting for Ollama service to start..."
sleep 5

# Pull a model for embeddings
echo "ğŸ“¦ Pulling Llama2 model for embeddings..."
ollama pull llama2:13b

# Stop the service
kill $OLLAMA_PID

echo ""
echo "ğŸ‰ Ollama setup complete!"
echo ""
echo "To use Ollama with ChunkyMonkey:"
echo "1. Start Ollama: ollama serve"
echo "2. Set your .env file with:"
echo "   OPENAI_API_KEY="
echo "   OLLAMA_BASE_URL=http://localhost:11434"
echo "   OLLAMA_MODEL=llama2:13b"
echo ""
echo "3. Run ChunkyMonkey: cargo run -- start"
echo ""
echo "ğŸ’ Ready to go bananas for chunks! ğŸŒ" 